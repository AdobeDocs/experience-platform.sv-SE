---
title: Funktionsomformningstekniker
description: L칛r dig mer om viktiga f칬rbehandlingstekniker som dataomvandling, kodning och funktionsskalning, som f칬rbereder data f칬r utbildning i statistiska modeller. Det t칛cker vikten av att hantera saknade v칛rden och konvertera kategoriserade data f칬r att f칬rb칛ttra modellens prestanda och precision.
role: Developer
source-git-commit: b248e8f8420b617a117d36aabad615e5bbf66b58
workflow-type: tm+mt
source-wordcount: '3437'
ht-degree: 5%

---

# Funktionsomvandlingstekniker

Transformeringar 칛r viktiga f칬rbearbetningssteg som konverterar eller skalar data till ett format som 칛r l칛mpligt f칬r modellutbildning och -analys, vilket ger optimala prestanda och precision. Det h칛r dokumentet fungerar som en extra syntaxresurs och inneh친ller detaljerad information om viktiga funktionsomformningstekniker f칬r f칬rbearbetning av data.

Maskinininl칛rningsmodeller kan inte direkt bearbeta str칛ngv칛rden eller null-v칛rden, vilket g칬r dataf칬rbearbetning n칬dv칛ndig. I den h칛r guiden beskrivs hur du anv칛nder olika omformningar f칬r att imputera saknade v칛rden, konvertera kategoriserade data till numeriska format och till칛mpa funktionens skalningstekniker, till exempel kodning och vektorisering med en aktivering. Dessa metoder g칬r det m칬jligt f칬r modeller att tolka och l칛ra sig effektivt av data, vilket i slut칛nden f칬rb칛ttrar deras prestanda.

## Automatisk funktionsomformning {#automatic-transformations}

Om du v칛ljer att hoppa 칬ver `TRANSFORM`-satsen i ditt `CREATE MODEL`-kommando utf칬rs funktionsomformningen automatiskt. Automatisk f칬rbearbetning av data inkluderar null-ers칛ttning och standardfunktionsomvandlingar (baserat p친 datatypen). Numeriska kolumner och textkolumner imputeras automatiskt, och funktionsomformningar utf칬rs f칬r att s칛kerst칛lla att data har ett l칛mpligt format f칬r maskininl칛rningsmodellutbildning. Den h칛r processen inkluderar dataimputering som saknas samt kategoriserade, numeriska och booleska omformningar.

>[!IMPORTANT]
>
>Den funktionsomvandling som anv칛nds vid tidpunkten f칬r utbildningen kommer ocks친 att anv칛ndas f칬r funktionsomformning vid tidpunkten f칬r f칬ruts칛gelse och utv칛rdering.

I f칬ljande tabeller beskrivs hur olika datatyper hanteras n칛r satsen `TRANSFORM` utel칛mnas under kommandot `CREATE MODEL`.

### Null-ers칛ttning {#automatic-null-replacement}

| Datatyp | Null-ers칛ttning |
|-----------------|-----------------------------------------------------|
| Numeriskt | Nuller ers칛tts med kolumnens medelv칛rde. |
| Kategorisisk | Nuller ers칛tts med nyckelordet `ml_unknown`. |
| Boolean | Nulls ers칛tts med ett `FALSE`-v칛rde. |
| Tidsst칛mpel | Det h칛r f칬rv칛ntas vara ett kontinuerligt f칛lt. |
| Kapslad/STRUKTUR | Ers칛ttningen beror p친 bladnodens datatyp. |

### Omvandling av funktioner {#automatic-feature-transformation}

| Datatyp | Funktionsomvandling |
|-----------------|-----------------------------------------------------|
| Numeriskt | INTE OBLIGATORISKT - Eftersom den h칛r datatypen tolkas av maskininl칛rningsalgoritmer. |
| Str칛ng | Str칛ngindexering sker. |
| Boolean | Str칛ngindexering sker. |
| Tidsst칛mpel | Ingen 친tg칛rd utf칬rs. |
| STRUCT | V칛rdet expanderas till sin l칬vnod. Omvandlingen sker baserat p친 l칬vnodens datatyp. |

**exempel**

```sql
CREATE model modelname options(model_type='logistic_reg', label='rating') AS SELECT * FROM movie_rating;
```

## Manuella funktionsomvandlingar {#manual-transformations}

Om du vill definiera anpassad f칬rbearbetning av data i `CREATE MODEL`-satsen anv칛nder du `TRANSFORM`-satsen i kombination med valfritt antal tillg칛ngliga omformningsfunktioner. Dessa manuella f칬rbearbetningsfunktioner kan ocks친 anv칛ndas utanf칬r `TRANSFORM`-satsen. Alla omformningar som beskrivs i avsnittet [transformator nedan](#available-transformations) kan anv칛ndas f칬r att f칬rbearbeta data manuellt.

### Viktiga egenskaper

F칬ljande 칛r viktiga egenskaper i funktionsomformningen som du b칬r t칛nka p친 n칛r du definierar f칬rbearbetningsfunktionerna:

- **Syntax**: `TRANSFORM(functionName(colName, parameters) <aliasNAME>)`
   - Aliasnamnet 칛r obligatoriskt i syntaxen. Du m친ste ange ett aliasnamn, annars misslyckas fr친gan.

- **Parametrar**: Parametrarna 칛r positioneringsargument. Det inneb칛r att varje parameter bara kan ta vissa v칛rden. Mer information om vilken funktion som tar vilket argument finns i respektive dokumentation.

- **Klinande transformatorer**: Utdata fr친n en transformator kan bli indata till en annan transformator.

- **Funktionsanv칛ndning**: Den senaste funktionsomvandlingen anv칛nds som en funktion i maskininl칛rningsmodellen.

**Exempel**

```sql
CREATE MODEL modelname 
TRANSFORM(
  string_imputer(language, 'adding_null') AS imp_language, 
  numeric_imputer(users_count, 'mode') AS imp_users_count, 
  string_indexer(imp_language) AS si_lang,  
  vector_assembler(array(imp_users_count, si_lang, watch_minutes)) AS features
)  
OPTIONS(MODEL_TYPE='logistic_reg', LABEL='rating') 
AS SELECT * FROM df;
```

## Tillg칛ngliga omformningar {#available-transformations}

Det finns 19 tillg칛ngliga omformningar. Dessa omformningar delas upp i [Allm칛nna omformningar](#general-transformations), [Numeriska omformningar](#numeric-transformations), [Kategoriomformningar](#categorical-transformations) och [Textuella omformningar](#textual-transformations).

### Allm칛nna omformningar {#general-transformations}

I det h칛r avsnittet finns mer information om de transformatorer som anv칛nds f칬r ett stort antal datatyper. Den h칛r informationen 칛r viktig om du beh칬ver anv칛nda omformningar som inte 칛r specifika f칬r kategoriserade data eller textdata.

>[!NOTE]
>
>Datatypen input avser den kolumn som imputation till칛mpas p친. Datatypen output avser den kolumn som skapas som utdata n칛r omformningen har b칬rjat g칛lla.

#### Numerisk imputer {#numeric-imputer}

Transformeraren **Numerisk imputer** slutf칬r saknade v칛rden i en dataupps칛ttning. Detta anv칛nder antingen medelv칛rdet, medianen eller l칛get f칬r de kolumner d칛r de saknade v칛rdena finns. Indatakolumnerna ska vara antingen `DoubleType` eller `FloatType`. Mer information och exempel finns i dokumentationen f칬r [Spark-algoritmen](https://spark.apache.org/docs/2.2.0/ml-features.html#imputer).

>[!NOTE]
>
>Alla null-v칛rden i indatakolumner behandlas som saknade och d칛rf칬r ocks친 imputerade.

**Datatyper**

- Indatatyp: Numerisk
- Datatyp f칬r utdata: Numerisk

**Definition**

```sql
transformer(numeric_imputer(hour, 'mean') hour_imputed)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
| -------- | ------------ | ----- | -------- | -------- |
| `STRATEGY` | En imputeringsstrategi. De tillg칛ngliga v칛rdena 칛r: [`mean`, `median`, `mode`]. | string | medelv칛rde | valfri |

{style="table-layout:auto"}

**Exempel f칬re imputation**

| id | timme |
|---|---|
| 0 | 18,0 |
| 1 | noll |
| 2 | 8,0 |

**Exempel efter imputation (med medelstrategi)**

| id | timme |
|---|---|
| 0 | 18,0 |
| 1 | 13,0 |
| 2 | 8,0 |

#### Str칛ngimputer {#string-imputer}

Transformeraren **String imputer** slutf칬r saknade v칛rden i en dataupps칛ttning med en str칛ng som anges av anv칛ndaren som ett funktionsargument. Indata- och utdatakolumnerna ska vara datatypen `string`.

>[!NOTE]
>
>Alla null-v칛rden i indatakolumner behandlas som saknade och ers칛tts med den angivna str칛ngen.

**Datatyper**

- Indatatyp: String
- Datatyp f칬r utdata: String

**Definition**

```sql
transform(string_imputer(name, 'unknown_name') as name_imputed)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
| -------- | ------------ | ----- | -------- | -------- |
| `NULL_REPLACEMENT` | V칛rdet som ers칛tter null-v칛rden. | string | ml_unknown | valfri |

{style="table-layout:auto"}

**Exempel f칬re imputation**

| id | name |
|---|---|
| 0 | John |
| 1 | noll |
| 2 | Alice |

**Exempel efter imputation (anv칛nder &#39;ml_unknown&#39; som ers칛ttning)**

| id | name |
|---|---|
| 0 | John |
| 1 | ml_unknown |
| 2 | Alice |

#### Boolean imputer {#imputer}

Transformeraren **Boolean imputer** slutf칬r saknade v칛rden i en dataupps칛ttning f칬r en boolesk kolumn. Indata- och utdatakolumnerna ska vara av typen `Boolean`.

>[!NOTE]
>
>Alla null-v칛rden i indatakolumner behandlas som saknade och ers칛tts med det angivna booleska v칛rdet.

**Datatyper**

- Indatatyp: Boolean
- Datatyp f칬r utdata: Boolean

**Definition**

```sql
transform(boolean_imputer(name, true) as name_imputed)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
| -------- | ------------ | ----- | -------- | -------- |
| `NULL_REPLACEMENT` | Boolean imputer. Till친t v칛rden: [`true`, `false`]. | boolesk | false | valfri |

**Exempel f칬re imputation**

| id | flagga |
|---|---|
| 0 | true |
| 1 | noll |
| 2 | false |

**Exempel efter imputation (anv칛nder &#39;true&#39; som ers칛ttning)**

| id | flagga |
|---|---|
| 0 | true |
| 1 | true |
| 2 | false |

#### Vektormonterare {#vector-assembler}

Transformatorn `VectorAssembler` kombinerar en angiven lista med indatakolumner till en enda vektorkolumn, vilket g칬r det enklare att hantera flera funktioner i maskininl칛rningsmodeller. Detta 칛r s칛rskilt anv칛ndbart n칛r du vill sammanfoga r친funktioner och funktioner som genererats av olika funktionstransformerare i en enda funktionsvektor. `VectorAssembler` accepterar indatakolumner av numeriska, booleska och vektortyper. I varje rad sammanfogas v칛rdena f칬r indatakolumnerna till en vektor i den angivna ordningen.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#vectorassembler) -->

**Datatyper**

- Indatatatyp: `array[string]` (kolumnnamn med numeriska v칛rden/matrisv칛rden [numeriska v칛rden])
- Utdatatyp: `Vector[double]`

**Definition**

```sql
transform(vector_assembler(id, hour, mobile, userFeatures) as features)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
| -------- | ------------ | ----- | -------- | -------- |
| NA | Inga ytterligare parametrar kr칛vs f칬r den h칛r transformatorn. | NA | NA | NA |

{style="table-layout:auto"}

**Exempel f칬re omformning**

| id | timme | mobil | userFeatures | klickad |
|---|-------|--------|------------------|---------|
| 0 | 18 | 1,0 | [0.0, 10.0, 0.5] | 1,0 |

{style="table-layout:auto"}

**Exempel efter omformning**

| id | timme | mobil | userFeatures | klickad | funktioner |
|---|------|--------|------------------|---------|-------------------------------|
| 0 | 18 | 1,0 | [0.0, 10.0, 0.5] | 1,0 | [18.0, 1.0, 0.0, 10.0, 0.5] |

{style="table-layout:auto"}

### Numeriska omformningar {#numeric-transformations}

L칛s det h칛r avsnittet om du vill veta mer om de tillg칛ngliga transformatorerna f칬r bearbetning och skalning av numeriska data. Dessa transformatorer beh칬vs f칬r att hantera och optimera numeriska funktioner i dataupps칛ttningarna.

#### Binarizer {#binarizer}

Transformeraren `Binarizer` konverterar numeriska funktioner till bin칛ra (0/1) funktioner via en process som kallas binarisering. Funktionsv칛rden som 칛r st칬rre 칛n det angivna tr칬skelv칛rdet konverteras till 1,0, medan v칛rden som 칛r lika med eller mindre 칛n tr칬skelv칛rdet konverteras till 0,0. `Binarizer` st칬der b친de `Vector`- och `Double`-typer f칬r indatakolumnen.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer). -->

**Datatyper**

- Indatatyp: Numerisk kolumn
- Datatyp f칬r utdata: Numerisk

**Definition**

```sql
transform(numeric_imputer(rating, 'mode') rating_imp, binarizer(rating_imp) rating_binarizer)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|------------|----------------------------------------------------------------------------------------------------------|----------|----------|----------|
| `THRESHOLD` | Param f칬r tr칬skelv칛rdet som anv칛nds f칬r att bin칛ra kontinuerliga funktioner. Funktioner som 칛r st칬rre 칛n tr칬skelv칛rdet 칛r bin칛ra till 1,0, medan funktioner som 칛r lika med eller mindre 칛n tr칬skelv칛rdet 칛r bin칛ra till 0,0. | int/double | 0,0 | valfri |

{style="table-layout:auto"}

**Exempel p친 indata f칬re binarisering**

| id | v칛rdering |
|---|---------|
| 0 | -18,0 |
| 1 | 13,0 |
| 2 | 8,0 |

**Exempelutdata efter binarisering (standardtr칬skelv칛rde 0,0)**

| id | v칛rdering |
|---|---------|
| 0 | 0,0 |
| 1 | 1,0 |
| 2 | 1,0 |

**Definition med anpassat tr칬skelv칛rde**

```sql
transform(numeric_imputer(age, 'mode') age_imp, binarizer(age_imp, 14.0) age_binarizer)
```

**Exempelutdata efter binarisering (med tr칬skelv칛rdet 14.0)**

| id | age |
|---|-------|
| 0 | 0,0 |
| 1 | 0,0 |
| 2 | 1,0 |

#### Bucketizer {#bucketizer}

Transformeraren `Bucketizer` konverterar en kolumn med kontinuerliga funktioner till en kolumn med funktionsintervall, baserat p친 anv칛ndardefinierade tr칬skelv칛rden. Den h칛r processen 칛r anv칛ndbar n칛r du vill segmentera kontinuerliga data i diskreta beh친llare eller fickor. `Bucketizer` kr칛ver en `splits`-parameter som definierar gr칛nserna f칬r bucketerna.

**Datatyper**

- Indatatyp: Numerisk kolumn
- Datatyp f칬r utdata: Numeriska (bundna v칛rden)

**Definition**

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling, min_max_scaler(maxScaling) as features)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|----------|----------|
| `splits` | En parameter f칬r att mappa kontinuerliga funktioner till grupper. Med `n+1` delningar finns det `n` bucket. Delningar m친ste vara i strikt 칬kande ordning och intervallet (x,y) anv칛nds f칬r varje hink utom den sista, som inkluderar y. | array(double) | N/A | valfri |

{style="table-layout:auto"}

**Exempel p친 delningar**

- Array(Double.NegativeInfinity, 0.0, 1.0, Double.PositiveInfinity)
- Array(0.0, 1.0, 2.0)

Delningar ska omfatta hela intervallet med dubbla v칛rden. Annars behandlas v칛rden utanf칬r de angivna delningarna som fel.

**Exempelomformning**

Det h칛r exemplet tar en kolumn med kontinuerliga funktioner (`course_duration`), binder den enligt `splits` och s칛tter sedan ihop de resulterande bucklarna med andra funktioner.

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling, min_max_scaler(maxScaling) as features)
```

#### MinMaxScaler {#minmaxscaler}

Transformatorn `MinMaxScaler` skalar om varje funktion i en vektorradupps칛ttning till ett angivet intervall, vanligtvis [0, 1]. Detta garanterar att alla funktioner bidrar lika mycket till modellen. Det 칛r s칛rskilt anv칛ndbart f칬r modeller som 칛r k칛nsliga f칬r funktionsskalning, till exempel 칬vertoningsbaserade algoritmer. `MinMaxScaler` arbetar med f칬ljande parametrar:

- **min**: Omvandlingens nedre gr칛ns, som delas av alla funktioner. Standardv칛rdet 칛r `0.0`.
- **max**: Omvandlingens 칬vre gr칛ns, som delas av alla funktioner. Standardv칛rdet 칛r `1.0`.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#minmaxscaler).  -->

**Datatyper**

- Indatatyp: `Array[Double]`
- Utdatatyp: `Array[Double]`

**Definition**

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling, min_max_scaler(maxScaling) as features)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|--------------------------------------------------------------------------------------------------|------|---------|----------|
| `min` | L칛gre gr칛ns efter omvandling, delas av alla funktioner. | double | 0,0 | valfri |
| `max` | 칐vre gr칛ns efter omvandling, delad med alla funktioner. | double | 1,0 | valfri |

**Exempelomformning**

I det h칛r exemplet omformas en upps칛ttning funktioner och de skalas om till det angivna intervallet med MinMaxScaler efter att flera andra omformningar har anv칛nts.

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling, min_max_scaler(maxScaling) as features)
```

#### MaxAbsScaler {#maxabsscaler}

Transformatorn `MaxAbsScaler` skalar om varje funktion i en vektorradupps칛ttning till intervallet [-1, 1] genom att dividera med det maximala absoluta v칛rdet f칬r varje funktion. Den h칛r omformningen 칛r idealisk f칬r att bevara glans i dataupps칛ttningar med b친de positiva och negativa v칛rden, eftersom data inte flyttas eller centreras. Detta g칬r `MaxAbsScaler` s칛rskilt l칛mplig f칬r modeller som 칛r k칛nsliga f칬r skalan av indatafunktioner, t.ex. s친dana som innefattar distansber칛kningar.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#maxabsscaler). -->

**Datatyper**

- Indatatyp: `Array[Double]`
- Utdatatyp: `Array[Double]`

**Definition**

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|---------------------------------------------------------------------------------------------------------|------|---------|----------|
| NA | MaxAbsScaler kr칛ver inga ytterligare parametrar f칬r 친tg칛rden. | NA | NA | NA |

**Exempelomformning**

I det h칛r exemplet anv칛nds flera omformningar, inklusive `MaxAbsScaler`, f칬r att skala om funktioner till intervallet [-1, 1].

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, max_abs_scaler(vec_assembler) as maxScaling)
```

#### Normaliserare {#normalizer}

`Normalizer` 칛r en transformator som normaliserar varje vektor i en vektorradupps칛ttning s친 att den har en enhetsnorm. Denna process garanterar en konsekvent skala utan att vektorernas riktning 칛ndras. Den h칛r omvandlingen 칛r s칛rskilt anv칛ndbar i maskininl칛rningsmodeller som bygger p친 avst친ndsm친tt eller andra vektorbaserade ber칛kningar, s칛rskilt n칛r vektorernas storlek varierar avsev칛rt.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#normalizer) -->

**Datatyper**

- Indatatyp: `array[double]` / `vector[double]`
- Utdatatyp: `vector[double]`

**Definition**

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, normalizer(vec_assembler, 3) as normalized)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|----------------------------------------------------------------------------------------|---------|---------|----------|
| `p` | Anger `p-norm` som anv칛nds f칬r normalisering (till exempel `1-norm`, `2-norm`). | heltal | 2 | valfri |

**Exempelomformning**

I det h칛r exemplet visas hur du anv칛nder flera omformningar, inklusive `Normalizer`, f칬r att normalisera en upps칛ttning funktioner med den angivna `p-norm`.

```sql
TRANSFORM(binarizer(time_spent, 5.0) as binary, bucketizer(course_duration, array(-440.5, 0.0, 150.0, 1000.7)) as buck_features, vector_assembler(array(buck_features, users_count, binary)) as vec_assembler, normalizer(vec_assembler, 3) as normalized)
```

#### QuantileDiscretizer {#quantilediscretizer}

`QuantileDiscretizer` 칛r en transformator som konverterar en kolumn med kontinuerliga funktioner till binda kategorisiska funktioner, med det antal beh친llare som best칛ms av parametern `numBuckets`. I vissa fall kan det faktiska antalet bucklar vara mindre 칛n det angivna antalet om det finns f칬r f친 distinkta v칛rden f칬r att skapa tillr칛ckligt m친nga kvantiteter.

Den h칛r omvandlingen 칛r s칛rskilt anv칛ndbar n칛r du vill f칬renkla representationen av kontinuerliga data eller f칬rbereda dem f칬r algoritmer som fungerar b칛ttre med kategoriserade indata.

**Datatyper**

- Indatatyp: Numerisk kolumn
- Datatyp f칬r utdata: Numerisk kolumn (kategorisisk)

**Definition**

```sql
TRANSFORM(quantile_discretizer(hour, 3) as result)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|--------------|--------------------------------------------------------------------------------------------------------------------------|---------|---------|----------|
| `NUM_BUCKETS` | Det antal grupper (kvantiteter eller kategorier) som datapunkter grupperas i. Talet m친ste vara st칬rre 칛n eller lika med tv친. | heltal | 2 | valfri |

**Exempelomformning**

I det h칛r exemplet visas hur `QuantileDiscretizer` binder en kolumn med kontinuerliga funktioner (`hour`) till tre kategorier.

```sql
TRANSFORM(quantile_discretizer(hour, 3) as result)
```

**Exempel f칬re och efter diskretisering**

| id | timme | resultat |
|---|------|--------|
| 0 | 18,0 | 2,0 |
| 1 | 19,0 | 2,0 |
| 2 | 8,0 | 1,0 |
| 3 | 5,0 | 1,0 |
| 4 | 2,2 | 0,0 |

#### StandardScaler {#standardscaler}

`StandardScaler` 칛r en transformator som normaliserar varje funktion i en vektorradupps칛ttning s친 att den har en enhetsstandardavvikelse och/eller nollmedelv칛rde. Den h칛r processen g칬r data mer l칛mpliga f칬r algoritmer som antar att funktioner centreras runt noll med en konsekvent skala. Omvandlingen 칛r s칛rskilt viktig f칬r maskininl칛rningsmodeller som SVM, logistisk regression och neurala n칛tverk, d칛r icke standardiserade data kan leda till konvergensproblem eller minskad precision.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#standardscaler).  -->

**Datatyper**

- Indatatyp: Vector
- Datatyp f칬r utdata: Vektor

**Definition**

```sql
TRANSFORM(standard_scaler(feature) as ss_features)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|------------|------------------------------------------------------------------------------------------------------|---------|---------|----------|
| `withStd` | Skalar data s친 att de har enhetsstandardavvikelse. | boolesk | True | valfri |
| `withMean` | Centrerar data med medelv칛rdet f칬re skalning. Det h칛r alternativet ger t칛ta utdata, s친 anv칛nd f칬rsiktighet med sparse-indata. | boolesk | Falskt | valfri |

**Exempelomformning**

I det h칛r exemplet visas hur du anv칛nder StandardScaler p친 en upps칛ttning funktioner och normaliserar dem med enhetsstandardavvikelse och nollmedelv칛rde.

```sql
TRANSFORM(standard_scaler(feature) as ss_features)
```

### Kategoriserade omformningar {#categorical-transformations}

I det h칛r avsnittet finns en 칬versikt 칬ver de tillg칛ngliga transformatorerna f칬r att konvertera och f칬rbearbeta kategoriserade data f칬r maskininl칛rningsmodeller. Dessa omformningar 칛r utformade f칬r datapunkter som representerar distinkta kategorier eller etiketter, i st칛llet f칬r numeriska v칛rden.

#### StringIndexer {#stringindexer}

`StringIndexer` 칛r en transformator som kodar en str칛ngkolumn med etiketter till en kolumn med numeriska index. Indexv칛rdena ligger mellan 0 och `numLabels` och sorteras efter etikettfrekvens (den vanligaste etiketten f친r indexv칛rdet 0). Om indatakolumnen 칛r numerisk byts den till en str칛ng f칬re indexering. Osynliga etiketter kan tilldelas indexet `numLabels` om det anges av anv칛ndaren.

Den h칛r omvandlingen 칛r s칛rskilt anv칛ndbar n칛r du vill konvertera kategoriserade str칛ngdata till numeriska format, vilket g칬r den l칛mplig f칬r maskininl칛rningsmodeller som kr칛ver numeriska indata.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#stringindexer) -->

**Datatyper**

- Indatatyp: String
- Datatyp f칬r utdata: Numerisk

**Definition**

```sql
TRANSFORM(string_indexer(category) as si_category)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|-------------|------|---------|----------|
| NA | `StringIndexer` kr칛ver inga ytterligare parametrar f칬r 친tg칛rden. | NA | NA | NA |

**Exempelomformning**

I det h칛r exemplet visas hur du anv칛nder `StringIndexer` p친 en kategorisisk funktion och konverterar den till ett numeriskt index.

```sql
TRANSFORM(string_indexer(category) as si_category)
```

#### OneHotEncoder {#onehotencoder}

`OneHotEncoder` 칛r en transformator som konverterar en kolumn med etikettindex till en kolumn med null-optimerade bin칛ra vektorer, d칛r varje vektor har h칬gst ett enda v칛rde. Den h칛r kodningen 칛r s칛rskilt anv칛ndbar f칬r att till친ta att algoritmer som kr칛ver numeriska indata, t.ex. Logistisk regression, kan inf칬rliva kategoriserade data effektivt.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#onehotencoder).  -->

**Datatyper**

- Indatatyp: Numerisk
- Datatyp f칬r utdata: Vector[Int]

**Definition**

```sql
TRANSFORM(string_indexer(category) as si_category, one_hot_encoder(si_category) as ohe_category)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|-------------|------|---------|----------|
| NA | OneHotEncoder kr칛ver inga ytterligare parametrar f칬r 친tg칛rden. | NA | NA | NA |

**Exempelomformning**

I det h칛r exemplet visas hur du f칬rst till칛mpar `StringIndexer` p친 en kategoriseringsfunktion och sedan anv칛nder `OneHotEncoder` f칬r att konvertera indexerade v칛rden till en bin칛r vektor.

```sql
TRANSFORM(string_indexer(category) as si_category, one_hot_encoder(si_category) as ohe_category)
```

### Textuella omvandlingar {#textual-transformations}

I det h칛r avsnittet finns information om de omvandlare som 칛r tillg칛ngliga f칬r bearbetning och konvertering av textdata till format som kan anv칛ndas i maskininl칛rningsmodeller. Detta avsnitt 칛r mycket viktigt f칬r utvecklare som arbetar med naturliga spr친kdata och textanalys.

#### CountVectorizer {#countvectorizer}

`CountVectorizer` 칛r en transformator som konverterar en samling textdokument till vektorer f칬r tokenantal, vilket skapar glesare representationer baserat p친 det vokabul칛r som extraherats fr친n corpus. Den h칛r omvandlingen 칛r v칛sentlig f칬r att konvertera textdata till ett numeriskt format som kan anv칛ndas av maskininl칛rningsalgoritmer, som LDA (Latent Dirichlet Allocation), genom att representera frekvensen av tokens i varje dokument.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#countvectorizer). -->

**Datatyper**

- Indatatyp: Array[String]
- Datatyp f칬r utdata: T칛t vektor

**Definition**

```sql
TRANSFORM(count_vectorizer(texts) as cv_output)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------|---------|----------|
| `VOCAB_SIZE` | Maximal storlek p친 spr친ket. CountVectorizer skapar en ordbok som bara tar h칛nsyn till de `vocabSize` mest anv칛nda termerna som ordnas efter termfrekvens i korpus. | Int | 218 | valfri |
| `MIN_DOC_FREQ` | Anger det minsta antal olika dokument som en term m친ste finnas i f칬r att inkluderas i ordlistan. Kan vara ett absolut tal eller en br친kdel av dokument (om det 칛r en dubbel). | Dubbel | 1,0 | valfri |
| `MAX_DOC_FREQ` | Anger det maximala antalet olika dokument som en term kan finnas i f칬r att inkluderas i ordlistan. Kan vara ett absolut tal eller en br친kdel av dokument (om det 칛r en dubbel). | Dubbel | (263)-1 | valfri |
| `MIN_TERM_FREQ` | Filtrerar ut s칛llsynta ord i ett dokument. Termer med frekvens/antal som 칛r mindre 칛n det angivna tr칬skelv칛rdet ignoreras. Kan vara ett absolut tal eller en br친kdel av dokumentets tokenantal. | Dubbel | 1,0 | valfri |

{style="table-layout:auto"}

**Exempelomformning**

I det h칛r exemplet visas hur CountVectorizer konverterar en samling med textarrayer till vektorer med tokenantal, vilket ger en glesare representation.

```sql
TRANSFORM(count_vectorizer(texts) as cv_output)
```

**Exempel f칬re och efter vektorisering**

| id | texter | cv_output |
|----|---------------------------------|-----------------------------------|
| 0 | Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) | (3,[0,1,2],[1.0,1.0,1.0]) |
| 1 | Array(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;) | (3,[0,1,2],[2.0,2.0,1.0]) |

{style="table-layout:auto"}

#### NGram {#ngram}

`NGram` 칛r en transformator som genererar en sekvens av n-gram, d칛r n-gram 칛r en sekvens av (??) tokens (vanligtvis ord) f칬r ett heltal (`洧녵`). Utdata best친r av blankstegsavgr칛nsade str칛ngar av &#39;?&#39; p친 varandra f칬ljande ord, som kan anv칛ndas som funktioner i maskininl칛rningsmodeller, s칛rskilt s친dana som 칛r inriktade p친 bearbetning av naturligt spr친k.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#n-gram). -->

**Datatyper**

- Indatatyp: Array[String]
- Datatyp f칬r utdata: Array[String]

**Definition**

```sql
TRANSFORM(tokenizer(review_comments) as token_comments, ngram(token_comments, 3) as n_tokens)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|-----------------------------------------------------------------------------------------------|---------|-------------------|----------|
| `N` | Den minsta n-graml칛ngden m친ste vara st칬rre 칛n eller lika med 1. | heltal | 2 (funktioner i gram) | valfri |

{style="table-layout:auto"}

**Exempelomformning**

I det h칛r exemplet visas hur NGram-transformatorn skapar en sekvens p친 3 gram fr친n en lista med tokens som h칛rletts fr친n textdata.

```sql
TRANSFORM(tokenizer(review_comments) as token_comments, ngram(token_comments, 3) as n_tokens)
```

**Exempel f칬re och efter n-gram-omvandling**

| id | texter | n_tokens |
|----|-------------------------------------------------------|-------------------------------------------------------|
| 0 | [&quot;this&quot;, &quot;was&quot;, &quot;an&quot;, &quot;entertaining&quot;, &quot;movie&quot;] | [&quot;this was an&quot;, &quot;was an underh친llande&quot;, &quot;an underh친llande movie&quot; ] |

{style="table-layout:auto"}

#### StopWordsRemover {#stopwordsremover}

`StopWordsRemover` 칛r en transformator som tar bort stoppord fr친n en str칛ngsekvens och filtrerar bort vanliga ord som inte har n친gon v칛sentlig betydelse. Den tar en sekvens med str칛ngar som indata (till exempel utdata fr친n en tokeniserare) och tar bort alla stoppord som anges av parametern `stopWords`.

Den h칛r omvandlingen 칛r anv칛ndbar f칬r f칬rbearbetning av textdata, vilket f칬rb칛ttrar effektiviteten i maskininl칛rningsmodeller l칛ngre fram i kedjan genom att eliminera ord som inte bidrar mycket till den 칬vergripande inneb칬rden.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#stopwordsremover) -->

**Datatyper**

- Indatatyp: Array[String]
- Datatyp f칬r utdata: Array[String]

**Definition**

```sql
TRANSFORM(stop_words_remover(raw) as filtered)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|--------------------|--------------------------------------------------------------------------------------------------|---------------|-------------------------|----------|
| `stopWords` | Orden som ska filtreras bort. | matris [str칛ng] | Standard: engelska stoppord | valfri |

{style="table-layout:auto"}

<!-- Q) should this be the `CUSTOM_STOP_WORDS` parameter or the `stopWords` parameter?  -->

**Exempelomformning**

I det h칛r exemplet visas hur `StopWordsRemover` filtrerar bort vanliga engelska stoppord fr친n en lista med tokens.

```sql
TRANSFORM(stop_words_remover(raw) as filtered)
```

**Exempel p친 borttagning av stoppord f칬re och efter**

| id | r친format | filtrerad |
|----|------------------------------|--------------------------|
| 0 | [Jag, s친g,,, r칬d, ballong] | [s친g, r칬d, ballong] |
| 1 | [Mary, hade, ett litet lamm] | [Mary, liten, lamm] |

**Exempel med egna stoppord**

I det h칛r exemplet visas hur du anv칛nder en anpassad lista med stoppord f칬r att filtrera bort specifika ord fr친n indatasekvenserna.

```sql
TRANSFORM(stop_words_remover(raw, array("red", "I", "had")) as filtered)
```

**Exempel p친 borttagning av egna stoppord f칬re och efter**

| id | r친format | filtrerad |
|----|------------------------------|--------------------------|
| 0 | [Jag, s친g,,, r칬d, ballong] | [s친g,,, ballong] |
| 1 | [Mary, hade, ett litet lamm] | [Mary, en liten, lamm] |

#### TF-IDF {#tf-idf}

`TF-IDF` (frekvens f칬r omv칛nd termsekvens) 칛r en transformator som anv칛nds f칬r att m칛ta vikten av ett ord i ett dokument i f칬rh친llande till ett corpus. Termfrekvens (TF) avser det antal g친nger en term \(t\) visas i ett dokument \(d\), medan dokumentfrekvens (DF) anger hur m친nga dokument i korpus \(D\) som inneh친ller termen \(t\). Den h칛r metoden anv칛nds ofta vid textbrytning f칬r att minska effekten av ofta f칬rekommande ord, som&quot;a&quot;,&quot;the&quot; och&quot;of&quot;, som inneh친ller lite unik information.

Den h칛r omvandlingen 칛r s칛rskilt v칛rdefull n칛r det g칛ller textbrytning och bearbetning av naturliga spr친k eftersom den tilldelar ett numeriskt v칛rde till varje ords betydelse i ett dokument och i hela corpus.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#tf-idf) -->

**Datatyper**

- Indatatyp: Array[String]
- Datatyp f칬r utdata: Vector[Int]

**Definition**

```sql
create table td_idf_model transform(tokenizer(sentence) as token_sentence, tf_idf(token_sentence) as tf_sentence, vector_assembler(array(tf_sentence)) as feature) OPTIONS()
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------------|----------------------------------------------------------------------------------------|------|---------|----------|
| `NUM_FEATURES` | Antalet funktioner som ska genereras. M친ste vara st칬rre 칛n 0. | Int | 262144 | valfri |
| `MIN_DOC_FREQ` | Det minsta antal dokument i vilka en term m친ste framst친 som inkluderad i modellen. | Int | 0 | valfri |

{style="table-layout:auto"}

**Exempelomformning**

I det h칛r exemplet visas hur du anv칛nder TF-IDF f칬r att omvandla tokeniserade meningar till en funktionsvektor som representerar vikten av varje term i sammanhanget f칬r hela corpus.

```sql
create table td_idf_model transform(tokenizer(sentence) as token_sentence, tf_idf(token_sentence) as tf_sentence, vector_assembler(array(tf_sentence)) as feature) OPTIONS()
```

#### Tokenior {#tokenizer}

`Tokenizer` 칛r en transformator som delar upp text, t.ex. en mening, i enskilda termer, vanligtvis ord. Den konverterar meningar till arrayer med variabler, vilket utg칬r ett grundl칛ggande steg i textf칬rbearbetningen som f칬rbereder data f칬r vidare textanalys eller modelleringsprocesser.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#tokenizer) -->

**Datatyper**

- Indatatyp: Textmening
- Datatyp f칬r utdata: Array[String]

**Definition**

```sql
create table td_idf_model transform(tokenizer(sentence) as token_sentence, tf_idf(token_sentence) as tf_sentence, vector_assembler(array(tf_sentence)) as feature) OPTIONS()
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|-----------|-------------|------|---------|----------|
| NA | `Tokenizer` kr칛ver inga ytterligare parametrar f칬r 친tg칛rden. | NA | NA | NA |

**Exempelomformning**

I det h칛r exemplet visas hur `Tokenizer` delar upp meningar i enskilda ord (tokens) som en del av en textbearbetningsprocess.

```sql
create table td_idf_model transform(tokenizer(sentence) as token_sentence, tf_idf(token_sentence) as tf_sentence, vector_assembler(array(tf_sentence)) as feature) OPTIONS()
```

#### Word2Vec {#word2vec}

`Word2Vec` 칛r en uppskattare som bearbetar ordsekvenser som representerar dokument och utbildar en `Word2VecModel`. Den h칛r modellen mappar varje ord till en unik vektor med fast storlek och omvandlar varje dokument till en vektor genom att ber칛kna ett genomsnitt f칬r vektorerna f칬r alla ord i dokumentet. Det anv칛nds ofta i naturliga spr친kbehandlings친tg칛rder. `Word2Vec` skapar ordinb칛ddningar som f친ngar in semantisk betydelse, konverterar textdata till numeriska vektorer som representerar relationerna mellan ord och m칬jligg칬r effektivare textanalys och maskininl칛rningsmodeller.

<!-- More information and examples can be found in the [Spark algorithm documentation](https://spark.apache.org/docs/2.2.0/ml-features.html#word2vec) -->

**Datatyper**

- Indatatyp: Array[String]
- Datatyp f칬r utdata: Vector[Double]

**Definition**

```sql
TRANSFORM(tokenizer(review) as tokenized, word2Vec(tokenized, 10, 1) as word2Vec)
```

**Parametrar**

| Parameter | Beskrivning | Typ | Standard | Valfritt |
|--------------|-----------------------------------------------------------------------------------------------------|---------|---------|----------|
| `VECTOR_SIZE` | Dimensionen f칬r den vektor som varje ord omformas till. | Heltal | 100 | valfri |
| `MIN_COUNT` | Det minsta antal g친nger en token m친ste finnas med i `Word2Vec`-modellens vokabul칛r. | Heltal | 5 | valfri |

{style="table-layout:auto"}

**Exempelomformning**

I det h칛r exemplet visas hur `Word2Vec` konverterar en tokeniserad granskning till en vektor med fast storlek som representerar medelv칛rdet f칬r ordvektorerna i dokumentet.

```sql
TRANSFORM(tokenizer(review) as tokenized, word2Vec(tokenized, 10, 1) as word2Vec)
```

**Exempel f칬re och efter Word2Vec-omformning**

| recension | tokeniserad | word2Vec |
|-------------------------------|--------------------------------------|---------------------------------|
| det h칛r var en underh친llande film | [this, was, an, underh친llande, movie] | [-0.02571388928294182,0.00818799751577899,0.0092235435 731709,-0.01515385233797133,0.012175946310162545,3.112906 5901041035E-4,0.002514510504261252,0.00575701978523284 3,-0.021328244300093502,0.00933587718750069] |

{style="table-layout:auto"}
